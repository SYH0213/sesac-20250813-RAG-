## RAG 핵심 개념 탐구 및 복습

rag는 기존의 이미 학습이 완료된 LLM은 최신 정보나 특정 딥한 정보에 대한 부분등 대답 할 수 없는 내용을 외부 데이터를 통해 그 정보를 이용해서 대답을 할 수 있게 해주는 기술이다.

기존 LLM은 앞에서도 말했듯이 학습됐을때의 정보만 알고 있기 때문에 예를들어 학습된 정보가 2025년 7월에 완료되었다면 현재 2025년 8월 13일 뉴스를 보여줘 라고 하면 알 수 없고, 혹은 유재석에 대해 알려줘 라고 했을때 정확한 정보를 알려줄 때도 있지만 알지 못하는 부분에 대해 잘못된 정보를 생성하는 할루시네이션 문제가 있을 수 있는 한계가 있다.

정보검색은 외부 문서(docx, pdf, csv) 등을 불러오는 것이고, 청크 분할은 불러온 문서를 일정 범위 혹은 의미 단위로 나눠서 모델이 검색하기 쉽도록 하는 작업이다.

임베딩은 분할된 청크를 고차원 벡터로 변환하여 이후 유사도를 구별할 수 있도록 하는 작업이고, 유사도 계산은 임베딩된 벡터들을 비교하여 각 단어 혹은 문장의 유사도를 계산하는 작업이다.

벡터 스토어 저장은 임베딩 해서 만들어진 벡터를 데이터베이스에 저장하고 색인화 하여 이후 질문이 들어왔을때 관련된 텍스트를 검색하기위한 데이터로 사용됨.

## chatgpt의 보완사항

1. RAG 필요성
“외부 데이터를 활용해 기존 LLM이 알 수 없는 정보에 대답하게 하는 기술”
→ 정확합니다. RAG는 LLM이 모르는 최신 정보·전문 정보·사내 데이터 등을 불러와 답변에 포함시키는 구조입니다.
✔️ 추가로 기억: Retrieval(검색) + Augmented Generation(증강 생성) 의 약자라는 점도 시험/면접에서 물어볼 수 있습니다.

2. 기존 LLM 한계
학습 시점 이후의 데이터 인식 불가

잘못된 정보 생성(Hallucination) 가능성

폐쇄형(Closed-book) 모델이라 외부 데이터 자동 검색 불가
→ 예시로 날짜를 든 건 아주 좋습니다. 이런 **“시점 예시”**는 이해도를 보여주는 데 도움이 됩니다.

3. 정보 검색 & 청크 분할
설명 정확합니다.

보완 포인트:

청크 크기는 보통 토큰 단위로 나누며(예: 500~1,000토큰)

오버랩(Overlap)을 주어 문맥이 끊기지 않게 함 (예: 500토큰 청크, 50토큰 오버랩)

4. 임베딩 & 유사도 계산
설명 잘하셨습니다.

보완 포인트:

임베딩은 “단어/문장을 고차원 벡터로 변환”이 맞지만,
여기서 “고차원”은 768, 1024, 1536차원 등 모델에 따라 다름

유사도 계산 시 가장 많이 쓰는 방식: 코사인 유사도(Cosine Similarity)

5. 벡터 스토어 저장
설명도 맞습니다.

보완 포인트:

저장 시 **Indexing(색인화)**를 해서 검색 속도 향상

대표 벡터DB 예시: FAISS(로컬), Pinecone·Weaviate(클라우드)